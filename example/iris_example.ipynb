{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Example: Simple ETL lane\n",
    "====================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: it is recommended to took a look at the [official documentation](https://sparklanes.readthedocs.io) first.*\n",
    "\n",
    "In this example, we'll build a simple ETL pipeline using sparklanes and the popular iris dataset. First, we'll load the dataset from CSV, before applying some transformations on it, to then finally dump it as JSON to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing all the libs we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "from sparklanes import Task, Lane, conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And write our data processors, or `Tasks` next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Task('extract_data')\n",
    "class ExtractIrisCSVData(object):\n",
    "    \"\"\"Load the iris data set from a CSV file\"\"\"\n",
    "    def __init__(self, iris_csv_path):\n",
    "        self.iris_csv_path = iris_csv_path\n",
    "\n",
    "    def extract_data(self):\n",
    "        # Read the csv\n",
    "        iris_df = conn.spark.read.csv(path=self.iris_csv_path,\n",
    "                                      sep=',',\n",
    "                                      header=True,\n",
    "                                      inferSchema=True)\n",
    "\n",
    "        # Make it available to tasks that follow\n",
    "        self.cache('iris_df', iris_df)\n",
    "\n",
    "\n",
    "@Task('add_index')\n",
    "class AddRowIndex(object):\n",
    "    \"\"\"Add a index to each row in the data set\"\"\"\n",
    "    def add_index(self):\n",
    "        # Add id column\n",
    "        self.iris_df = self.iris_df.withColumn('id', monotonically_increasing_id())\n",
    "\n",
    "        # Update cache\n",
    "        self.cache('iris_df', self.iris_df)\n",
    "\n",
    "\n",
    "@Task('normalize')\n",
    "class NormalizeColumns(object):\n",
    "    \"\"\"Normalize all numerical columns\"\"\"\n",
    "    def normalize(self):\n",
    "        # Add normalized columns\n",
    "        columns = self.iris_df.columns\n",
    "        columns.remove('species')\n",
    "        for col in columns:\n",
    "            col_min = float(self.iris_df.agg({col: \"min\"}).collect()[0]['min(%s)' % col])\n",
    "            col_max = float(self.iris_df.agg({col: \"max\"}).collect()[0]['max(%s)' % col])\n",
    "            self.iris_df = self.iris_df.withColumn(\n",
    "                col + '_norm', (self.iris_df[col] - col_min) / (col_max - col_min)\n",
    "            )\n",
    "\n",
    "        # Update Cache\n",
    "        self.cache('iris_df', self.iris_df)\n",
    "\n",
    "\n",
    "@Task('write_to_json')\n",
    "class SaveAsJSON(object):\n",
    "    \"\"\"Dump the data set as JSON to disk\"\"\"\n",
    "    def __init__(self, output_folder):\n",
    "        self.output_folder = output_folder\n",
    "\n",
    "    def write_to_json(self):\n",
    "        self.iris_df.write.format('json').save(self.output_folder)\n",
    "\n",
    "        # Clear cache\n",
    "        self.uncache('iris_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how in the extractor class, we cache our `DataFrame` using `self.cache`, and as a result make it an attribute to all tasks that follow.\n",
    "\n",
    "With our Tasks being defined, we can now build the lane:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane = (Lane(name='IrisExampleLane', run_parallel=False)\n",
    "        .add(ExtractIrisCSVData, iris_csv_path='data/iris.csv')\n",
    "        .add(AddRowIndex)\n",
    "        .add(NormalizeColumns)\n",
    "        .add(SaveAsJSON, 'out'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-07 11:52:01,466 - SPARKLANES - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "Executing `IrisExampleLane`\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2018-06-07 11:52:01,468 - SPARKLANES - INFO - \n",
      "================================================================================\n",
      "\tIrisExampleLane\n",
      "\t >Task_ExtractIrisCSVData\n",
      "\t >Task_AddRowIndex\n",
      "\t >Task_NormalizeColumns\n",
      "\t >Task_SaveAsJSON\n",
      "================================================================================\n",
      "2018-06-07 11:52:01,469 - SPARKLANES - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "Executing task `ExtractIrisCSVData.extract_data`\n",
      "--------------------------------------------------------------------------------\n",
      "2018-06-07 11:52:01,668 - SPARKLANES - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "Finished executing task `ExtractIrisCSVData.extract_data`. Execution time: 0:00:00.198397\n",
      "--------------------------------------------------------------------------------\n",
      "2018-06-07 11:52:01,669 - SPARKLANES - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "Executing task `AddRowIndex.add_index`\n",
      "--------------------------------------------------------------------------------\n",
      "2018-06-07 11:52:01,675 - SPARKLANES - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "Finished executing task `AddRowIndex.add_index`. Execution time: 0:00:00.004853\n",
      "--------------------------------------------------------------------------------\n",
      "2018-06-07 11:52:01,676 - SPARKLANES - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "Executing task `NormalizeColumns.normalize`\n",
      "--------------------------------------------------------------------------------\n",
      "2018-06-07 11:52:02,848 - SPARKLANES - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "Finished executing task `NormalizeColumns.normalize`. Execution time: 0:00:01.170293\n",
      "--------------------------------------------------------------------------------\n",
      "2018-06-07 11:52:02,849 - SPARKLANES - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "Executing task `SaveAsJSON.write_to_json`\n",
      "--------------------------------------------------------------------------------\n",
      "2018-06-07 11:52:03,065 - SPARKLANES - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "Finished executing task `SaveAsJSON.write_to_json`. Execution time: 0:00:00.215517\n",
      "--------------------------------------------------------------------------------\n",
      "2018-06-07 11:52:03,066 - SPARKLANES - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "Finished executing `IrisExampleLane`\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sparklanes._framework.lane.Lane at 0x1034bf5f8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lane.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That works, but what makes `sparklanes` more useful, is the capability of defining processing lanes using *YAML configuration files*, to then submit these lanes to a spark cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define the same lane as above like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "lane:\n",
    "  name: IrisExampleLane\n",
    "  run_parallel: false\n",
    "  tasks:\n",
    "    - class: tasks.iris.ExtractIrisCSVData\n",
    "      kwargs:\n",
    "        iris_csv_path: data/iris.csv\n",
    "    - class: tasks.iris.AddRowIndex\n",
    "    - class: tasks.iris.NormalizeColumns\n",
    "    - class: tasks.iris.SaveAsJSON\n",
    "      args:\n",
    "        - out\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the file being saved as `iris.yml`, our directory structure looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "data/  \n",
    "  iris.csv  \n",
    "tasks/  \n",
    "  __init__.py  # Required to be recognized as a python package  \n",
    "  iris.py  # Contains our processor classes (Tasks)  \n",
    "iris.yml  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to run our pipeline, we can submit it to spark using the `lane-submit` command line script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-07 11:50:09,219 - SPARKLANES - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "Executing `IrisExampleLane`\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2018-06-07 11:50:09,219 - SPARKLANES - INFO - \n",
      "================================================================================\n",
      "\tIrisExampleLane\n",
      "\t >Task_ExtractIrisCSVData\n",
      "\t >Task_AddRowIndex\n",
      "\t >Task_NormalizeColumns\n",
      "\t >Task_SaveAsJSON\n",
      "================================================================================\n",
      "2018-06-07 11:50:09,219 - SPARKLANES - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "Executing task `ExtractIrisCSVData.extract_data`\n",
      "--------------------------------------------------------------------------------\n",
      "2018-06-07 11:50:13,784 - SPARKLANES - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "Finished executing task `ExtractIrisCSVData.extract_data`. Execution time: 0:00:04.564362\n",
      "--------------------------------------------------------------------------------\n",
      "2018-06-07 11:50:13,784 - SPARKLANES - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "Executing task `AddRowIndex.add_index`\n",
      "--------------------------------------------------------------------------------\n",
      "2018-06-07 11:50:13,818 - SPARKLANES - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "Finished executing task `AddRowIndex.add_index`. Execution time: 0:00:00.033710\n",
      "--------------------------------------------------------------------------------\n",
      "2018-06-07 11:50:13,818 - SPARKLANES - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "Executing task `NormalizeColumns.normalize`\n",
      "--------------------------------------------------------------------------------\n",
      "2018-06-07 11:50:16,216 - SPARKLANES - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "Finished executing task `NormalizeColumns.normalize`. Execution time: 0:00:02.398010\n",
      "--------------------------------------------------------------------------------\n",
      "2018-06-07 11:50:16,216 - SPARKLANES - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "Executing task `SaveAsJSON.write_to_json`\n",
      "--------------------------------------------------------------------------------\n",
      "2018-06-07 11:50:16,833 - SPARKLANES - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "Finished executing task `SaveAsJSON.write_to_json`. Execution time: 0:00:00.616633\n",
      "--------------------------------------------------------------------------------\n",
      "2018-06-07 11:50:16,833 - SPARKLANES - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "Finished executing `IrisExampleLane`\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "lane-submit -y iris.yml -p tasks -e data -s master=local[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it. Please check out the [documentation](https://sparklanes.readthedocs.io) for explanations on how more complex processing lanes can be built."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
